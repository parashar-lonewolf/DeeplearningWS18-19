{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A very simple MNIST classifier.\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from datasets import MNISTDataset\n",
    "# from show_comp_graph import show_graph\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNISTDataset(\"./MNIST_IMAGES\", batch_size=100,seed=int(time()))\n",
    "## normalizing the values\n",
    "mnist.train_data = mnist.train_data/256\n",
    "mnist.test_data = mnist.test_data/256\n",
    "## one hot encoding of the labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "mnist.train_labels = onehot_encoder.fit_transform(mnist.train_labels.reshape(-1, 1))\n",
    "mnist.test_labels = onehot_encoder.fit_transform(mnist.test_labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the training data\n",
    "print(\"[\",len(mnist.train_data),\",\",len(mnist.train_data[0]),\"]\")\n",
    "print(\"[\",len(mnist.train_labels),\",\",len(mnist.train_labels[0]),\"]\")\n",
    "## the testing data\n",
    "print(\"[\",len(mnist.test_data),\",\",len(mnist.test_data[0]),\"]\")\n",
    "print(\"[\",len(mnist.test_labels),\",\",len(mnist.test_labels[0]),\"]\")\n",
    "# ## the validation data\n",
    "# print(\"[\",len(mnist.validation.images),\",\",len(mnist.validation.images[0]),\"]\")\n",
    "# print(\"[\",len(mnist.validation.labels),\",\",len(mnist.validation.labels[0]),\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## printing to peek at a flattened imageand its label\n",
    "# print(mnist.train_data[0])\n",
    "# print(mnist.train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the global variable and the main function for doing everything basically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # Import data\n",
    "    global mnist\n",
    "    \n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    \n",
    "    y = tf.matmul(x, W) + b\n",
    "    \n",
    "    # one hidden layer //linear\n",
    "    W1 = tf.Variable(tf.zeros([784, 10]))\n",
    "    b1 = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.matmul(x, W1) + b1\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#     # The cross-entropy\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "    print(\"entropy done\")\n",
    "    tf.summary.scalar(\"cost\", cross_entropy)\n",
    "    \n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "#     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    sess = tf.InteractiveSession()\n",
    "    writer = tf.summary.FileWriter(\"/Tensorboard_Sem3\", sess.graph) ## source file to store tensorboard files\n",
    "    tf.global_variables_initializer().run()\n",
    "    merged = tf.summary.merge_all()\n",
    "    print(\"model creation done, training about to start\")\n",
    "    # Train\n",
    "    for step in range(1000):\n",
    "        batch_xs, batch_ys = mnist.next_batch()\n",
    "#         print(\"step \"+ str(step)+\" running\")\n",
    "        stats, _ = sess.run([merged,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        writer.add_summary(stats, step)\n",
    "    print(\"training done\")    \n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    show_graph(tf.get_default_graph().as_graph_def())\n",
    "    print(\"The accuracy:\")\n",
    "    print(sess.run(accuracy, feed_dict={x: mnist.test_data,\n",
    "                                      y_: mnist.test_labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
