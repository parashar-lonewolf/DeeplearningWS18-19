import os

import numpy as np


class MNISTDataset:
    """'Bare minimum' class to wrap MNIST numpy arrays into a dataset."""
    def __init__(self, data_folder, batch_size, shuffle=True, seed=None):
        """
        data_folder should be the directory where the numpy arrays are located.
        Use seed optionally to always get the same shuffling (-> reproducible results)
        """
        self.batch_size = batch_size
        self.train_data = np.load(os.path.join(data_folder, "mnist_train_imgs.npy"))
        self.train_labels = np.load(os.path.join(data_folder, "mnist_train_lbls.npy"))
        self.test_data = np.load(os.path.join(data_folder, "mnist_test_imgs.npy"))
        self.test_labels = np.load(os.path.join(data_folder, "mnist_test_lbls.npy"))
        self.size = self.train_data.shape[0]

        if seed:
            np.random.seed(seed)
        if shuffle:
            self.shuffle_train()
        self.shuffle = shuffle
        self.current_pos = 0

    def next_batch(self):
        """Either gets the next batch, or optionally shuffles and starts a new epoch."""
        end_pos = self.current_pos + self.batch_size
        if end_pos <= self.size:
            batch = (self.train_data[self.current_pos:end_pos],
                     self.train_labels[self.current_pos:end_pos])
            self.current_pos += self.batch_size
        else:  # we return what's left (-> smaller batch!) and prepare the start of a new epoch
            batch = (self.train_data[self.current_pos:self.size],
                     self.train_labels[self.current_pos:self.size])
            if self.shuffle:
                self.shuffle_train()
            self.current_pos = 0
            print("Starting new epoch...")
        return batch

    def shuffle_train(self):
        shuffled_inds = np.arange(self.train_data.shape[0])
        np.random.shuffle(shuffled_inds)
        self.train_data = self.train_data[shuffled_inds]
        self.train_labels = self.train_labels[shuffled_inds]
